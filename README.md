# RoboNet



### 内容简述

* 红色车、蓝色车物体检测模块（YOLO v3）
* 在上步得到Bounding Box（ROI）内进行车轮、装甲板、尾灯检测模块（YOLO v3）
* 根据ROI估算战车在ROI坐标中的朝向角（卷积+全连接预测角度的sin与cos值）
* 像素图与地图之间坐标变换
* 基于卡尔曼滤波与匈牙利算法的车辆位置与角度跟踪

### 红色车、蓝色车物体检测模块（YOLO v3）

* 采用YOLO v3的Tiny版本，输入为416x416的RGB图，输出BoundingBox的位置、尺寸、置信度及类别概率

* loss图：![image-20200218230134551](/Users/minghao/Library/Application Support/typora-user-images/image-20200218230134551.png)

* 网络结构图（把Darknet53换成19， 两个多尺度预测）：

  ![image-20200218231947277](/Users/minghao/Library/Application Support/typora-user-images/image-20200218231947277.png)

### 车轮、装甲板、尾灯检测模块

* 与红蓝车检测模型基本相同，只是输入尺寸改为288x288，输出类别有：车轮、红1装甲板、红2装甲板、蓝1装甲板、蓝2装甲板、红尾灯、蓝尾灯
* 将车检测与车的特征检测分开的原因：
  * 在输出尺寸416x416的情况下，直接检测所有特征可能分辨率不够
  * 类别变多会使网络运行速度变慢(影响不大)
  * 使得车的特征定位更精确，有利于之后估计车在世界坐标下的位置

### 根据ROI估算战车在ROI坐标中的朝向角

* 尝试过基于颜色、边界特征估算车的朝向角，人工寻找特征较为麻烦，且效果不够理想，所以最终采用神经网络预测

* 输入96x96x1的灰度图

* 输出该图对应朝向角的cos，sin值（没有直接预测角度，因为0度和360度实际朝向一样，这会给损失的计算带来麻烦）

  * 朝向正右方时角度为0（cos=1，sin=0）
  * 朝向正下时角度为90（cos=0，sin=1）

* 之后可以根据尺寸缩放调整cos，sin值，获得原始尺寸下的朝向角

* loss

  ![image-20200218233139320](/Users/minghao/Library/Application Support/typora-user-images/image-20200218233139320.png)

### 像素图与地图之间坐标变换

* 首先通过张正有标定法，标定了所用哨岗相机，得到了哨岗相机内参
* 之后在实际应用中，选择地图与像素图大于等于4个点对，计算出地图到像素图的单应性矩阵，已知内参矩阵通过SolvePnP得到相机的外参
* 可实现已知某特征像素点坐标及该特征在世界坐标的高度，反解出该特征在世界坐标系下的坐标

### 基于卡尔曼滤波与匈牙利算法的车辆位置与角度跟踪

* 在得到检测结果后，可得到每个检测到的bounding box属于ID（红1、红2、蓝1、蓝2）的概率矩阵，再计算坐标变换后的车位置与卡尔曼滤波预测位置的IOU矩阵
* 将上述两个矩阵相加，通过匈牙利算法选出每个检测结果对应的ID，进而更新卡尔曼滤波器